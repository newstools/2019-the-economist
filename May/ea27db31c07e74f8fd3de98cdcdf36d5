 ON MAY 14th, San Francisco’s legislature voted to ban city agencies from using facial-recognition technology. Leading the charge was Aaron Peskin, a member of the city's Board of Supervisors, the legislative body. In January, when he introduced the measure, he said he had “yet to be persuaded that there is any beneficial use of this technology that outweighs the potential for government actors to use it for coercive and oppressive ends.” That argument proved compelling. Just one of the city’s nine supervisors opposed the ban (though she acknowledged it was “a well-intended piece of legislation”) and the mayor will probably soon sign it into law.  The measure does not ban private citizens or businesses from using facial=recognition technology, or from sharing with police what any facial-recognition enabled cameras gather, subject to board approval. Taylor Swift used the technology to identify stalkers; stadiums have used it to identify banned fans and people transmitting data to bookies. Both of those uses remain legal in San Francisco. The bill does not prevent the technology’s use at airports and ports, which are federally regulated. Nor will anyone who is already using it have to stop: San Francisco’s police department has not deployed it. The ban is designed not to stop abuses, but to prevent them, and to ensure that citizens have a voice in how they are watched and policed. The potential for abuse is vast. Technology such as facial-recognition cameras and automatic licence-plate readers can gather images constantly and store them indefinitely. They make surveillance cheap and invisible. Compiling a record of, say, everyone who walks or drives past a given intersection over the course of a day no longer requires teams of police officers to stand on the corner noting what they see. That type of surveillance costs money and manpower, and lets people see that they are being seen. Cameras atop light-posts are effectively invisible (generally, people only see them when they look for them), always on and feed images into a searchable database where they can reside forever. Some may shrug, believing that since their phones already track them, and their social-media accounts provide a record of their preferences, travel, and in many cases political beliefs, one more incursion on their privacy does not amount to much. But facial-recognition technology is rather different. A person can choose to leave their phone at home, or delete their social-media accounts. To avoid being tracked in a city blanketed with facial-recognition cameras, they would have to stay home. As pro-police as most Americans are, most would probably prefer to be able to cross the street without the government knowing exactly where and when they did so. What this type of technology really imperils is the space for disobedience built into any humane system of laws. It narrows—and makes possible it possible to eliminate—a tension: on one hand, people want laws to be enforced consistently and impartially, as they should. But they also do not want to be fined every time they jaywalk or exceed the speed limit. Anyone inclined to scoff at the notion of governments enforcing all the laws all of the time should bear in mind how local governments' budgets depend on fines and fees from on their citizens. That sort of enforcement may not happen tomorrow, but facial-recognition enabled cameras make it possible. America is not yet at that point. Facial-recognition is not currently widely used. It is reported not to work especially well in non-controlled settings—it cannot always compare and identify people at odd angles, in motion and under bad lighting. It grows less accurate as a database gets larger, and it is especially bad at accurately identifying non-white people. But it is getting better and more popular. Most places are neither as tech-savvy nor as liberal as San Francisco and they may not support an outright ban. But other places should take a hard look at the other mandate enacted by San Francisco’s legislation. It requires city agencies to obtain approval from the city’s board of supervisors before they buy any surveillance technology, to write policies governing its use and to report annually on how often and why they used it. It does not bar agencies from obtaining the technology they deem appropriate; it just prevents them from doing so in secret. This sort of oversight should be routine. But it is rare. Just nine cities (and one county) have similar ordinances on the books, with roughly another two dozen cities and states considering them. Banning technology that the police want might be a step too far for some cities. But ensuring that those empowered to kill and arrest in the community’s name must be accountable to the community is not.