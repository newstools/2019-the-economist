“PATIENT ZERO” is a medical term that started as a misunderstanding. An early North American victim of AIDS was anonymised in some documents as “Patient O”. The individual in question, Gaëtan Dugas, a Canadian flight attendant, was thought at the time to have been the point of origin of the North American AIDS epidemic. The misreading of O (for “Outside of California”) as 0 (ie, zero), though accidental to begin with, thus seemed propitious. In fact, Dugas was not the sole point of that epidemic’s origin. But the term stuck, and has spread. It has, indeed, spread beyond medicine to embrace another sort of plague—disinformation. Demaskuok, which means “debunk” in Lithuanian, is a piece of software that searches for the patient zeros of fake news. It was developed by Delfi, a media group headquartered in Lithuania’s capital, Vilnius, in conjunction with Google, a large American information-technology company. It works by sifting through reams of online verbiage in Lithuanian, Russian and English, scoring items for the likelihood that they are disinformation. Then, by tracking back through the online history of reports that look suspicious, it attempts to pin down a disinformation campaign’s point of origin—its patient zero.  Demaskuok identifies its suspects in many ways. One is to search for wording redolent of themes propagandists commonly exploit. These include poverty, rape, environmental degradation, military shortcomings, war games, societal rifts, viruses and other health scares, political blunders, poor governance, and, ironically, the uncovering of deceit. And because effective disinformation stirs the emotions, the software gauges a text’s ability to do that, too. Items with terms like “current-account deficit” are less likely to be bogus than those that mention children, immigrants, sex, ethnicities, animals, national heroes and injustice. Gossip and scandal are additional tip-offs. Verbiage about sports and the weather is less likely to fire up outrage, so the software scores items about those subjects as less suspicious. Another clue is that disinformation is crafted to be shared. Demaskuok therefore measures “virality”—the number of times readers share or write about an item. The reputations of websites that host an item or provide a link to it provide additional information. The software even considers the timing of a story’s appearance. Fake news is disproportionately posted on Friday evenings when many people, debunkers included, are out for drinks. Disinformers can be careless, too. Demaskuok therefore remembers the names of people quoted in fake news, as they sometimes crop up again. It also runs image searches to find other places a picture has been posted. Some, it turns out, first appeared before the events they supposedly document. Others also appear on websites with a reputation for disinformation, such as RT and Sputnik—both news outlets backed by Russia’s government. Russian-sponsored disinformation of this sort is a bane everywhere, but it is particularly rife in Estonia, Latvia and Lithuania—the three countries that, in 1990, were the first to declare independence from the Soviet Union, catalysing that union’s disintegration. The Baltic states, as they are often known collectively, then exacerbated their offence by joining NATO and the European Union. Russia, the Soviet Union’s puppetmaster, has neither forgiven nor forgotten. One consequence is that the Baltic states are particular targets for falsehoods intended to confuse and destabilise. Demaskuok is part of the fightback. It has improved since Delfi’s journalists began using it a year ago. It can now flag up not just total fabrications, but also more cunning trickery that works by exaggeration or omission. Viktoras Dauksas, who runs Debunk EU, a charity in Vilnius that was created in June to develop the technology further, says it can now even sometimes spot “broken mirrors”. This is his term for disinformation in which facts are technically accurate but presented selectively to mislead. Russian disinformation, he says, has become increasingly treacherous, with truthful elements savvily “twisted in a way to undermine democracy”. Demaskuok is pretty good. About half the items it flags prove, under human scrutiny, to be disinformation. That scrutiny, though, is an important part of the process. Some of it comes from Demaskuok’s users. Besides Delfi, these include Lithuania’s foreign ministry and a score of news outlets, think-tanks, universities and other organisations. After studying an item that the software considers disinformation, people in these organisations tell the system if it was on or off the mark. That improves future performance. Demaskuok is also supported by more than 4,000 volunteers known as “elves”. About 50 of them scroll through Demaskuok’s feed of suspected disinformation, selecting items to be verified. These are sent to the other elves for fact checking. Reports on the findings are then written up by the software’s users and emailed to newsrooms and other organisations, including Lithuania’s defence ministry, that produce written or video “debunks” for the public. The whole system typically moves so fast that an elf in Vilnius who goes by the alias “Vanagas” jokes it is like playing “Kremlin ping-pong”. This speed makes all the difference, says Vaidas Saldziunas, one of Delfi’s journalists. Wait too long and it may not matter if you “kill the patient zero, the original virus”, he says. If the resulting false narrative survives long enough, it may take on a life of its own. Officials say that abundant debunking has cultivated healthy scepticism in most Balts. But Eitvydas Bajarunas of Lithuania’s foreign ministry frets about disinformation’s effects on countries farther west, where fewer people fear Russian aggression. He points to a bogus report on September 25th that falsely claimed 22 German soldiers had desecrated a Jewish cemetery in Kaunas, a city 100km west of Vilnius. Neglect to nip such rot in the bud, he says, and political support in Germany for keeping troops in Lithuania could falter. Moreover, some worry that even Demaskuok’s success may play into Russia’s hands. Rob Procter, professor of social informatics at the University of Warwick, in Britain, offers a sobering thought. The Kremlin’s goal, he suggests, is not so much to convince Westerners that certain falsehoods are the truth. Rather, it wants its adversaries to doubt that anything can be trusted as true. If this is the aim, software that increases the number of news reports which get debunked may, paradoxically, have the opposite effect to that intended.■