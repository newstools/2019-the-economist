IN 1994 DOUGLAS RUSHKOFF shot onto the digital public sphere with “Cyberia: Life in the Trenches of Hyperspace.” With its distinctive, hallucinatory cover, the book was among the first to decode the nascent subculture of the internet to the mainstream public—and introduce Mr Rushkoff as a vibrant thinker of the online age. Fifteen books and a quarter of a century later, Mr Rushkoff’s view of the digital revolution has lost none of its idealism. But the early enthusiasm has turned into frustration. A technology capable of bringing people together increasingly drives them apart. A media system that could promote diverse views exhibits more concentration of power than existed offline. Mr Rushkoff’s latest book, “Team Human”, is a 100-point manifesto that howls at everything, from “antihuman” economics to artificial intelligence run on computers “built with rare earth metals and blood minerals” consuming “massive amounts of energy.” Everyone and everything seems to get a kicking. “Values once gave human society meaning and direction. Now this function is fulfilled by data.” Despite the alarm, Mr Rushkoff is optimistic that people will join forces and shape technology to ensure it upholds human values. “We are not alone,” he concludes. “Find the others.” An excerpt from the book on “the digital-media environment” appears below, followed by a short but respectfully combative interview. *       *      * The digital media environment From “Team Human” by Douglas Rushkoff (W.W. Norton, 2019): We were naive to think that digital technology would be intrinsically and inevitably more empowering than any medium that came before it. Yes, digital networks are more directionless and decentralized than their broadcast predecessors. They allow messages to flow from the bottom up, or the outside in. But, like all media, if they’re not consciously seized by the people seeking empowerment, they’ll be seized by someone or something else. Whoever controls media controls society. Each new media revolution appears to offer people a new opportunity to wrest that control from an elite few and reestablish the social bonds that media has compromised. But, so far anyway, the people—the masses—have always remained one entire media revolution behind those who would dominate them. For instance, ancient Egypt was organized under the presumption that the pharaoh could directly hear the words of the gods, as if he were a god himself. The masses, on the other hand, could not hear the gods at all; they could only believe. With the invention of text, we might have gotten a literate culture. But text was used merely to keep track of possessions and slaves. When writing was finally put in service of religion, only the priests could read the texts and understand the Hebrew or Greek in which they were composed. The masses could hear the Scriptures being read aloud, thus gaining the capability of the prior era—to hear the words of God. But the priests won the elite capability of literacy. When the printing press emerged in the Renaissance, the people gained the ability to read, but only the king and his chosen allies had the power to produce texts. Likewise, radio and television were controlled by corporations or repressive states. People could only listen or watch. With computers came the potential to program. Thanks to online networks, the masses gained the ability to write and publish their own blogs and videos—but this capability, writing, was the one enjoyed by the elites in the prior revolution. Now the elites had moved up another level, and were controlling the software through which all this happened. Today, people are finally being encouraged to learn code, but programming is no longer the skill required to rule the media landscape. Developers can produce any app they want, but its operation and distribution are entirely dependent on access to the walled gardens, cloud servers, and closed devices under the absolute control of just three or four corporations. The apps themselves are merely camouflage for the real activity occurring on these networks: the hoarding of data about all of us by the companies who own the platforms. Just as with writing and printing, we believe we have been liberated by the new medium into a boundless frontier, even though our newfound abilities are entirely circumscribed by the same old controlling powers.  At best, we are settling the wilderness for those who will later monopolize our new world. The problem with media revolutions is that we too easily lose sight of what it is that’s truly revolutionary. By focusing on the shiny new toys and ignoring the human empowerment potentiated by these new media—the political and social capabilities they are retrieving—we end up surrendering them to the powers that be. Then they, and we, become mere instruments for some other agenda. Social phenomena of all sorts undergo this process of hollowing. When punk rockers reduce their understanding of their movement to the right to wear Mohawks or pierce their faces, it’s easy for them to lose touch with the more significant anti-authoritarian ideology of DIY, direct action, and never selling out. Instead, punk becomes just another fashion trend to be sold at the mall. When ravers understand their movement as the right to take drugs and dance all night, they lose sight of the deeper political potentials unleashed by reclaiming public space or separating recreation from profit. Rave becomes just another genre for industry to sell. The styles of these movements were co-opted, and the essential shifts in power on which they were based were left behind. With digital technology, we too quickly let go of the social and intellectual empowerment offered by these new tools, leaving them to become additional profit centers for the already powerful. For example, the early internet enabled new conversations between people who might never have connected in real life. The networks compressed distance between physicists in California, hackers in Holland, philosophers in Eastern Europe, animators in Japan—and this writer in New York. These early discussion platforms also leveraged the fact that, unlike the TV or telephone, internet messaging didn’t happen in real time. Users would download net discussions, read them in their own time, offline, and compose a response after an evening of thought and editing. Then they would log back onto the net, upload the contribution, and wait to see what others thought. As a result, the internet became a place where people sounded and acted smarter than they do in real life. Imagine that: a virtual space where people brought their best selves, and where the high quality of the conversation was so valued that communities governed these spaces the way a farmers’ cooperative protects a common water supply. To gain access to the early internet, users had to digitally sign an agreement not to engage in any commercial activity. Advertising was expressly forbidden. Even the corporate search and social platforms that later came to monopolize the net originally vowed never to allow advertising because it would taint the humanistic cultures they were creating. Over time, enthusiasm for the intellectual purity of the net was overtaken by the need to appeal to investors. Business magazines announced that the internet could save the dying stock market by creating more room for the economy to grow—even if that additional real estate was virtual. A search engine designed to promote academic thought became the world’s biggest advertising agency, and a social media platform designed to help people connect became the world’s biggest data collector. Enthusiasts still associated the net with education and political power. They pushed for technology in schools and laptops in Africa, even though the digital society’s essential values had been left behind in the era of 2400-baud modems. The primary purpose of the internet had changed from supporting a knowledge economy to growing an attention economy. Instead of helping us leverage time to our intellectual advantage, the internet was converted to an “always on” medium, configured to the advantage of those who wanted to market to us or track our activities. Going online went from an active choice to a constant state of being. The net was strapped to our bodies in the form of smartphones and wearables that can ping or vibrate us to attention with notifications and updates, headlines and sports scores, social media messages and random comments. We have ended up living in a state of perpetual interruption that used to be endured only by 911 emergency operators or air traffic controllers, only we do it 24/7 and we pay for the privilege. The resulting disorientation is self-reinforcing. The more we are interrupted, the more distracted we become, and the less we avail ourselves of the real-world markers we use to ground ourselves. We become more easily manipulated and directed by the many technologies whose very purpose is to disorient us and control our behavior. We humans go from being the figure in a digital environment to being the ground. _____________ Excerpted from “Team Human.” Copyright © 2019 by Douglas Rushkoff. Used with permission of W.W. Norton, New York. All rights reserved. *       *      * An interview with Douglas Rushkoff The Economist: The premise of your book is that people need to become more human and resist the pathologies of digital technology. But humans created the technologies and enjoy using them. Aren’t you being utopian, relying on a change in human nature? Douglas Rushkoff: Humans created cigarettes, and people enjoy smoking them. Is it utopian to inform people about the health hazards of cigarettes? Perhaps. Likewise, humans working in social-media companies decided to port the addiction algorithms of slot machines into newsfeeds, in order to make engagement more addictive. And kids enjoy them. Is it utopian to suggest that technologies could be designed better? Especially now that so many people are learning about the bad actors in the social media space, is it foolish to suggest that we design technologies for humans to use, instead of technologies that use humans? I don't think so. I am not hoping for a utopian technology space. Just a better one. I think people are up for the challenge, and it wouldn’t require a fundamental transformation of the human species. The Economist: Your view of the economy is of a nefarious, self-serving, “antihuman” system that benefits a handful of people and companies to everyone else’s detriment. But capitalism has given us freedom, prosperity and lifted billions (literally) out of poverty. Aren’t you being one-sided? Mr Rushkoff: I’m an old-fashioned, Adam Smith economist. So I think that land, labour and capital all have equal roles as factors of production. By focusing on the power of capital, we emphasised growth for a long while now, with many benefits for civilisation. Yes, it required the conquest of whole continents and subjugation or elimination of certain races, but it definitely led to technological progress and better lives for many people. My concern is that optimising an entire economy for capital, alone, is itself rather “one-sided.” It forces all companies to scale, infinitely, and punishes those that achieve “right size.” So Twitter, for example, wasn't allowed to stop at just $2bn of annual revenue. That's partly because dividends and profits are taxed at much higher rates than capital gains. Now that we’re living in a digital economy, power-law dynamics amplify the rapid extraction of value from people and places. This is a problem for corporations as well. As Deloitte regularly reports in the Shift Index and as I documented in my last book, corporate profits relative to corporate size has been decreasing for 75 years. In market parlance, return on assets has been falling. Corporations have gotten good at taking all the money out of the marketplace, but increasingly bad at deploying it. It’s a form of economic obesity, where corporations grow but lose the ability to earn revenue from their operations. They can only approximate innovation by acquiring smaller companies. We don’t want our digital behemoths to amplify this trend. It is chiefly responsible for the increasing division of wealth we're witnessing today. When I go to speak at the shareholder meeting of a Fortune 100 company, and hear management chanting the mandated growth target for the coming year, I find it absurd. How big can Facebook and Amazon or even Coke and Starbucks get, why must they grow simply in order to survive, and to what lengths must they go in order to stoke that growth? Why is sustainable revenue an impossibility? So I think the last 400 years of expansion and wealth creation by chartered monopolies and scaled corporations may have reached a point of diminishing returns, and that we may want to explore business models where companies seek to find sustainable profits through their actual operations rather than unsustainable extraction, expansion and financialisation. The Economist: Is there a golden period that you want to harken back to? Is there a moment in time when you think the world went astray? Mr Rushkoff: I don’t think there’s a golden period from which we went astray. I simply think each of our terrific, connecting media and technologies—from language and text to education and currency—can end up working against their original purposes if we forget about where human beings fit in the equation. Public education, for example, was originally intended as compensation for workers. A man works in the coal mine all day, and deserves the dignity of being able to come home read and understand a novel or the newspaper. But over time, we’ve forgotten about the intrinsic value of education, and turned schools into an extension of job training. This leads to less interesting, intelligent and innovative adults. Likewise the Internet, with its tremendous potential for human connection, is now being used—intentionally—to generate fear and polarisation because that leads to more clicks and greater user predictability. So it’s a constant balancing act. There’s no utopia behind us, and no utopia ahead. The Economist: Your solution to the excesses and problems with the big web platforms is to slow them down rather than regulate them in a more surgical manner. Why do you think blunt measures are better? Mr Rushkoff: If anything, I am putting responsibility on the users rather than depending on regulation. I'm not a big fan of regulation, even though there has been some great success regulating internet companies in Europe. If these platforms are going to “slow down,” as you put it, it will be because we users are slowing down. I’m encouraging people to see every media technology they use as a drug. You are “on” Facebook,  “on” Snapchat, or even “on” Netflix. These technologies are exploiting everything we know about behavioural finance and Pavlovian triggers to evade our higher faculties and stimulate the brain stem. Go to Stanford, as I have, and sit in the classes where technologists are taught how to automate human behavior. Just look at the interfaces on consumer-grade stock-trading platforms, and how they have been designed to provoke uneducated users to make trades they don’t even fully understand. If we pause long enough to consciously “go online” rather than accept our constant connectivity as a given circumstance, we end up capable of expressing much more autonomy. The Economist: Your views and remedies are not centrist but extremist—and this is to describe them, not criticise them. Is this really the best way to achieve your values, rather than a more moderate path? Mr Rushkoff: The main argument of the book is that the fans of the singularity are wrong. They say that computers are about to become smarter than human beings, and human beings should accept their imminent extinction with grace and humility. I believe that’s a mistake, and that humans deserve a place in the digital future. If this is an extreme point of view, then it’s all the more important that I argue for it. I’m suggesting that instead of getting rid of humans, or even getting rid of technology, we should retrieve essential human values, and embed them in the technologies of tomorrow. Instead of working so hard to make technologies that thwart basic human cognition, we should build technologies that support and encourage human flourishing. I believe that being human is a team sport. Science supports the notion that evolution is more a collaborative than a competitive act. If we stop for a moment to realise this position is now considered extreme, we may all choose to become members of team human.