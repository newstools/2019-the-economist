PRESIDENT DONALD TRUMP is going to lose his re-election bid next year—or so recent surveys appear to suggest. A poll conducted between July 21st and 23rd on behalf of The Economist by YouGov, a pollster, found that Mr Trump would lose the national popular vote to a Democratic opponent by seven percentage points. A margin that large would be more than enough for a Democratic candidate such as Joe Biden, the former vice-president, or Elizabeth Warren, a senator from Massachusetts, to coast to a landslide victory in the Electoral College. However, it is currently more than 15 months before the election, and numbers released this early cannot accurately predict how candidates will perform. According to number-crunching from Christopher Wlezien and Robert Erikson, political scientists at the University of Texas and Columbia University, pre-election polls make for poor predictors until the close of summer in an election year, by which point both parties have held their nominating conventions. In their book “The 2012 Campaign and the Timeline of Presidential Elections”, they explain that candidates’ standing in the polls fails to account for even half of the variance in their eventual vote margins until the spring before the election. At 330 days before the contest—roughly December of the year before the election—polls show virtually no correlation to final election outcomes; today, 467 days before the 2020 election, they are even worse. One could make better predictions by flipping a coin than by looking at the polls.  Pollsters can blame a few factors for the errors in their early estimates. First, at this point in the campaign, the eventual candidates have not even been decided. It could be that Joe Biden will win the Democrats’ current primary contest, but such a bet is no sure thing. How can voters be expected to know for whom they will cast a ballot? It is also too early to know the eventual economic and political conditions of the election. By November 2020, the country could enter a recession, crushing Mr Trump’s odds of re-election. Or America could enter a new boom. It is also too far in advance of the election for most voters to be paying much attention to national politics. Forecasters seeking to predict elections with ample lead time may turn to information other than polling for more accuracy. Moody’s Analytics, a financial company, compiles economic data to use in predicting election outcomes, for example. The best projections also make use of economic indicators and the president’s approval ratings—which, while poll-based, are steadier and more frequently measured than the head-to-head match-ups. Nonetheless, these methods are far from perfect. Moody’s forecasts predicted with 95% confidence that Hillary Clinton would win the 2016 presidential election, and the best-known political-science model that relies on so-called “fundamentals” such as the economy and incumbency overshot Mr Trump’s popular vote margin by nearly three percentage points. Other scholars are devising new approaches for election prediction, but they are untested. Rachel Bitecofer, who studies public opinion at Christopher Newport University, has developed a method that eschews poll-based models in favour of state-level demographic data, such as how many white voters live in a state, and how far left or right it typically leans in presidential contests. She predicts that Mr Trump will lose his re-election bid in 2020. Her similarly-devised method performed worse than poll-based methods in 2018. Ms Bitecofer’s model explained 70% of the variance in congressional races—simply using the results from the last election would have predicted 95%—and it is doubtful that the relationships between demographic factors such as age and education and vote choice will remain constant from the mid-terms to 2020, as her model assumes. Her work also does not actually predict the chance Mr Trump will win next year, only his chances in every state. When asked for such a probability, Ms Bitecofer said it “wouldn’t be mathematically based”. Still, she is confident that there is “little to no chance” that Americans re-elect the president. The 2016 election instilled in voters a deep scepticism of polling, but is also served as a lesson to forecasters to be careful about how confidently they convey their predictions. There is danger in certainty. Two weeks before Mr Trump’s election, James Comey, then director of the FBI, made public an investigation into Hillary Clinton. He later said he did so because he “was making decisions in an environment where [Ms] Clinton was sure” to become the next president, a sentiment he attributed to pre-election polling and forecasting. Given the uncertainty of predictions made far in advance, why are they often taken seriously? The work of Nobel Prize-winning psychologist Daniel Kahneman and Amos Tversky (who would have also won the prize had he been alive when Mr Kahneman received it) provides some insight. In 1993, in a book chapter titled “Probabilistic Reasoning”, the two authors stipulate that improperly-calibrated forecasts are often accepted because they play on peoples’ biases. When predictions favour one side of the political aisle, as Ms Bitecofer’s and Moody’s currently happen to do, people who support that side are more likely to believe them. Messrs Kahneman and Tversky found that people often give too little weight to the underlying chance—the “prior probability”—of an outcome, favoring instead the most recent snippets of hard data that they see. In this case, the prior probability probably favours Mr Trump more than many forecasters believe. Punters at PredictIt, a website where users can wager on political events, give Mr Trump a roughly 50-50 shot of victory next year. With an average job approval of 43%, according to numbers crunched by the data-journalism website FiveThirtyEight, he is only just short of turning out the coalition that brought him to victory in 2016 with 46% of the vote. But many Democratic partisans will succumb to the temptation to believe soothing forecasts rather than confront such uncomfortable risks. The very opacity of complex statistical models can also create an illusion of validity, particularly when they come from a respected expert. But as George Box, a famous statistician, once said, “all models are wrong, but some are useful”. Forecasters and observers alike would do well to remember that.